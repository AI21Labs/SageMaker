{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Jurassic-2 Grande Instruct on SageMaker through Model Packages\n",
    "\n",
    "This sample notebook shows you how to deploy **Jurassic-2 Grande Instruct** using Amazon SageMaker.\n",
    "\n",
    "> **Note**: This is a reference notebook and it cannot run unless you make changes suggested in the notebook.\n",
    "\n",
    "## Pre-requisites:\n",
    "1. Before running this notebook, please make sure you got this notebook from the model catalog on SageMaker AWS Management Console.\n",
    "1. **Note**: This notebook contains elements which render correctly in Jupyter interface. Open this notebook from an Amazon SageMaker Notebook Instance or Amazon SageMaker Studio.\n",
    "1. Ensure that IAM role used has **AmazonSageMakerFullAccess**.\n",
    "1. This notebook is intended to work with **boto3 v1.25.4** or higher.\n",
    "\n",
    "## Contents:\n",
    "1. [Select model package](#1.-Select-model-package)\n",
    "2. [Create an endpoint and perform real-time inference](#2.-Create-an-endpoint-and-perform-real-time-inference)\n",
    "   1. [Create an endpoint](#A.-Create-an-endpoint)\n",
    "   2. [Interact with the model](#B.-Interact-with-the-model)\n",
    "   3. [Give it an instruction](#C.-Give-it-an-instruction)\n",
    "   4. [Create your own product description!](#D.-Create-your-own-product-description!)\n",
    "   5. [Delete the endpoint](#E.-Delete-the-endpoint)\n",
    "3. [Clean-up](#4.-Clean-up)\n",
    "    1. [Delete the model](#A.-Delete-the-model)\n",
    "    \n",
    "\n",
    "## Usage instructions\n",
    "You can run this notebook one cell at a time (By using Shift+Enter for running a cell)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Select model package\n",
    "Confirm that you received this notebook from the model catalog in SageMaker AWS Management Console."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_package_map = {\n",
    "    \"us-east-1\": \"arn:aws:sagemaker:us-east-1:416407187090:model-package/j2-grande-instruct-v1-0-20\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from sagemaker import ModelPackage\n",
    "from sagemaker import get_execution_role\n",
    "from sagemaker import ModelPackage\n",
    "import sagemaker as sage\n",
    "import boto3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check the version of boto3 - must be v1.25.4 or higher\n",
    "If you see a lower version number, pick another kernel to run the notebook, with Python 3.8 or above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.26.74'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boto3.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install ai21 python SDK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pip.repos.neuron.amazonaws.com\n",
      "Collecting ai21[SM]\n",
      "  Downloading ai21-1.0.2.tar.gz (8.2 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: requests in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from ai21[SM]) (2.28.1)\n",
      "Requirement already satisfied: boto3 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from ai21[SM]) (1.26.74)\n",
      "Requirement already satisfied: s3transfer<0.7.0,>=0.6.0 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from boto3->ai21[SM]) (0.6.0)\n",
      "Requirement already satisfied: botocore<1.30.0,>=1.29.74 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from boto3->ai21[SM]) (1.29.74)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from boto3->ai21[SM]) (1.0.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from requests->ai21[SM]) (1.26.8)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from requests->ai21[SM]) (2.1.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from requests->ai21[SM]) (2022.12.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from requests->ai21[SM]) (3.4)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from botocore<1.30.0,>=1.29.74->boto3->ai21[SM]) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.30.0,>=1.29.74->boto3->ai21[SM]) (1.16.0)\n",
      "Building wheels for collected packages: ai21\n",
      "  Building wheel for ai21 (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for ai21: filename=ai21-1.0.2-py3-none-any.whl size=15548 sha256=dc1f4ff22a3b5713faddac7068b8014356b2a5bf3d263cb11e8c1039bdba7e95\n",
      "  Stored in directory: /home/ec2-user/.cache/pip/wheels/7d/c9/1b/f6fa60c4ec9d74273fefb9ba4aca6ccc70ac3fdf740e597cd8\n",
      "Successfully built ai21\n",
      "Installing collected packages: ai21\n",
      "Successfully installed ai21-1.0.2\n"
     ]
    }
   ],
   "source": [
    "! pip install -U \"ai21[SM]\"\n",
    "import ai21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "region = boto3.Session().region_name\n",
    "if region not in model_package_map.keys():\n",
    "    raise (\"UNSUPPORTED REGION\")\n",
    "\n",
    "model_package_arn = model_package_map[region]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "role = get_execution_role()\n",
    "sagemaker_session = sage.Session()\n",
    "\n",
    "runtime_sm_client = boto3.client(\"runtime.sagemaker\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Create an endpoint and perform real-time inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to understand how real-time inference with Amazon SageMaker works, see [Documentation](https://docs.aws.amazon.com/sagemaker/latest/dg/deploy-model.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"j2-grande-instruct\"\n",
    "\n",
    "content_type = \"application/json\"\n",
    "\n",
    "real_time_inference_instance_type = (\n",
    "    \"ml.g5.12xlarge\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A. Create an endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------!"
     ]
    }
   ],
   "source": [
    "# create a deployable model from the model package.\n",
    "model = ModelPackage(\n",
    "    role=role, model_package_arn=model_package_arn, sagemaker_session=sagemaker_session\n",
    ")\n",
    "\n",
    "# Deploy the model\n",
    "predictor = model.deploy(1, real_time_inference_instance_type, endpoint_name=model_name, \n",
    "                         model_data_download_timeout=3600,\n",
    "                         container_startup_health_check_timeout=600,\n",
    "                        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once endpoint has been created, you would be able to perform real-time inference."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B. Interact with the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can think of Jurassic-2 Grande Instruct as a smart auto-completion algorithm: give it some text as input and it will generate some relevant text to naturally complete your input.\n",
    "\n",
    "These two helpful concepts are worth being familiar with:\n",
    "- **Prompt** - the input you provide to the model.\n",
    "- **Completion** - the output text the model generates."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Enter a simple prompt: \"To be, or\", and let the model complete it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " not to be: that is the question\n"
     ]
    }
   ],
   "source": [
    "response = ai21.Completion.execute(sm_endpoint=\"j2-grande-instruct\",\n",
    "                                   prompt=\"To be, or\",\n",
    "                                   maxTokens=4,\n",
    "                                   temperature=0,\n",
    "                                   numResults=1)\n",
    "\n",
    "print(response['completions'][0]['data']['text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the model identifies the beginning of a famous quote, and completes it correctly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C. Give it an instruction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model was specifically trained to follow natural language instructions. It is the most natural way to interact with large language models: simply tell the model what you want it to do, and it will follow.\n",
    "\n",
    "For this notebook, we will apply the model to creating a product description for an eCommerce site. Simply tell the model what you want it to do with a simple instruction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This funny t-shirt is perfect for anyone who enjoys a good laugh. It's made of 100% cotton and is soft and comfortable. The graphic on the front is bright and colorful, and it's sure to get attention. Whether you're wearing it to the gym, out with friends, or just around the house, this t-shirt is sure to make you smile.\n"
     ]
    }
   ],
   "source": [
    "instruction = \"\"\"Write an engaging product description for clothing eCommerce site.\n",
    "Product: Humor Men's Graphic T-Shirt.\n",
    "Description:\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "response = ai21.Completion.execute(sm_endpoint=\"j2-grande-instruct\",\n",
    "                                   prompt=instruction,\n",
    "                                   maxTokens=100,\n",
    "                                   temperature=0,\n",
    "                                   numResults=1)\n",
    "\n",
    "print(response['completions'][0]['data']['text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adjust the parameters\n",
    "A useful parameter is the temperature. **You can increase creativity by tweaking the temperature.** With temperature 0, the model will always choose the most probable completion, so it will always be the same. Increasing the temperature will provide varying completions, where the completion may be different with every generation. We recommend starting with a value of 0.7."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This funny t-shirt is perfect for anyone who enjoys a good joke. It's made from a soft cotton blend and is comfortable to wear. The graphic on the front features a humorous saying, and it's sure to make people laugh. This shirt is perfect for casual wear or special occasions.\n",
      "=============\n",
      "This t-shirt is perfect for anyone who wants to show off their sense of humor. The design features a funny saying on the front that will make you laugh. It's made of high-quality cotton, and it's comfortable to wear.\n",
      "\n",
      "Whether you're going out with friends or just relaxing at home, this t-shirt is a must-have. Order yours today!\n",
      "=============\n",
      "When life gives you lemons, make lemonade. But when life gives you lemons and lemonade, make lemon meringue pie. And that's exactly what this shirt is designed to do. This funny men's graphic t-shirt is perfect for anyone who enjoys a good joke and a delicious dessert. The shirt features an illustration of a lemon meringue pie, and the text \"When life gives you lemons and lemonade, make lemon meringue pie\" in bold letters. It's sure to bring a smile to your face every time you wear it. So next time life gives you lemons, don't fret - just grab this shirt and make the best of it.\n",
      "=============\n"
     ]
    }
   ],
   "source": [
    "instruction = \"\"\"Write an engaging product description for clothing eCommerce site.\n",
    "Product: Humor Men's Graphic T-Shirt.\n",
    "Description:\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "response = ai21.Completion.execute(sm_endpoint=\"j2-grande-instruct\",\n",
    "                                   prompt=instruction,\n",
    "                                   maxTokens=100,\n",
    "                                   temperature=0.7,\n",
    "                                   numResults=3)\n",
    "\n",
    "# Note that multiple completions - this is due to numResults > 1\n",
    "for comp in response['completions']:\n",
    "    print(comp['data']['text'].strip())\n",
    "    print(\"=============\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Be specific in your prompt\n",
    "You can see that the model generated several versions. There may be times when you are looking for a stricter format - such as a single paragraph. Just ask the model to stick to it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This funny t-shirt is perfect for anyone who likes to make jokes. It's made of 100% cotton and it's available in sizes S to 3XL. The t-shirt features a graphic of an old man with a cane and the words \"Old Fart\" printed on the front. It's sure to make your friends laugh!\n",
      "=============\n",
      "This funny men's graphic t-shirt is perfect for anyone who enjoys a good laugh. The shirt features an image of a dog wearing a cone on its head, and the caption reads, \"I can't touch my toes, but I can lick my own balls.\" It's sure to make people laugh and is perfect for any occasion.\n",
      "=============\n",
      "This funny t-shirt is perfect for the dad who loves to joke around. The shirt features a graphic of a bottle of beer and a lime with the words \"Dad Jokes\" printed below. It's sure to get a few laughs at the next family gathering.\n",
      "=============\n"
     ]
    }
   ],
   "source": [
    "instruction = \"\"\"Write an engaging product description for clothing eCommerce site. Make it a single paragraph.\n",
    "Product: Humor Men's Graphic T-Shirt.\n",
    "Description:\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "response = ai21.Completion.execute(sm_endpoint=\"j2-grande-instruct\",\n",
    "                                   prompt=instruction,\n",
    "                                   maxTokens=100,\n",
    "                                   temperature=0.5,\n",
    "                                   numResults=3)\n",
    "\n",
    "for comp in response['completions']:\n",
    "    print(comp['data']['text'].strip())\n",
    "    print(\"=============\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Personalize your prompt\n",
    "The model can generate nice descriptions based on only an instruction, but they may not be aligned with your actual product. If you have special features, ask the model to include them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This funny graphic t-shirt is perfect for anyone who wants to show their sense of humor. It's made of soft cotton and it's comfortable to wear all day long.\n",
      "=============\n",
      "This funny Einstein t-shirt is perfect for anyone who enjoys a good joke. The print is bright and colorful, and it's sure to get people talking. The shirt is made from soft cotton, and it's comfortable to wear.\n",
      "\n",
      "If you're looking for a unique and stylish t-shirt, the Humor Men's Graphic T-Shirt is the perfect choice.\n",
      "=============\n",
      "This t-shirt is perfect for anyone who wants to look stylish while showing off their sense of humor. The print is high quality and won't fade after washing. The shirt is made from soft cotton and fits true to size. It's perfect for wearing on a lazy day or for going out with friends.\n",
      "=============\n"
     ]
    }
   ],
   "source": [
    "instruction = \"\"\"Write an engaging product description for clothing eCommerce site. Make sure to include the following features in the description.\n",
    "Product: Humor Men's Graphic T-Shirt with a print of Einstein's quote: \"artificial intelligence is no match for natural stupidity”\n",
    "Features:\n",
    "- Soft cotton\n",
    "- Short sleeve\n",
    "Description:\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "response = ai21.Completion.execute(sm_endpoint=\"j2-grande-instruct\",\n",
    "                                   prompt=instruction,\n",
    "                                   maxTokens=100,\n",
    "                                   temperature=0.7,\n",
    "                                   numResults=3)\n",
    "\n",
    "for comp in response['completions']:\n",
    "    print(comp['data']['text'].strip())\n",
    "    print(\"=============\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### More format restrictions?\n",
    "If you have several examples of your optimal output, you can feed the model with a few-shot prompt that includes several examples. Prompts like this are very useful when you want to enforce a certain format that is non-trivial to pick up from just one example. These prompts work best with base models; try to use them with [Jurassic-2 Grande](https://github.com/AI21Labs/SageMaker/blob/main/J2_Grande_example_model_use.ipynb) instead."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### D. Create your own product description!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Want to build your own product description? Here's your chance!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions to build the prompt\n",
    "def list_features(features):\n",
    "    return \"\\n\".join(\n",
    "        f\"- {feat}\" for feat in features\n",
    "    )\n",
    "\n",
    "def build_prompt(product, features):\n",
    "    example = \"Write product descriptions for fashion eCommerce site. Make sure to include the following features in the description.\\n\"\n",
    "    example += f\"Product: {product}\\n\"\n",
    "    example += \"Features:\\n\"\n",
    "    example += list_features(features)\n",
    "    example += \"\\nDescription:\\n\"\n",
    "    \n",
    "    return example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Product: (for example, 'Women's Boho Beach Dress')Women's Boho Beach Dress\n",
      "Features, separated by commas with no spaces: (for example, 'midi dress,swing hem,special for summer')midi dress,swing hem,special for summer\n"
     ]
    }
   ],
   "source": [
    "product = input(\"Product: (for example, \\'Women's Boho Beach Dress\\')\")\n",
    "features = input(\"Features, separated by commas with no spaces: (for example, \\'midi dress,swing hem,special for summer\\')\")\n",
    "your_prompt = build_prompt(product, features.split(\",\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This boho beach dress is perfect for summer days! It's made of lightweight, flowy fabric and has a swing hem that moves with you. The midi length is perfect for warm weather, and the dress can easily be dressed up or down.\n",
      "=============\n",
      "This midi dress is perfect for summer! It's made from lightweight cotton and comes in a variety of colors, so you can choose your favorite. The swing hem adds a touch of fun and style, and the dress is loose and comfortable.\n",
      "=============\n",
      "This boho beach dress is the perfect choice for your next vacation! The midi length is flattering and swing hem adds a touch of movement. The fabric is perfect for summer, and you'll love the colorful print. Whether you're headed to the beach or just relaxing at home, this dress is a must-have.\n",
      "=============\n"
     ]
    }
   ],
   "source": [
    "response = ai21.Completion.execute(sm_endpoint=\"j2-grande-instruct\",\n",
    "                                   prompt=your_prompt,\n",
    "                                   maxTokens=100,\n",
    "                                   temperature=0.7,\n",
    "                                   numResults=3)\n",
    "\n",
    "for comp in response['completions']:\n",
    "    print(comp['data']['text'].strip())\n",
    "    print(\"=============\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interested in learning more?\n",
    "Take a look at our [blog post](https://www.ai21.com/blog/building-cv-profile-generator-using-ai21-studio) to understand the process of building a good prompt."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### E. Delete the endpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that you have successfully performed a real-time inference, you do not need the endpoint any more. You can terminate the endpoint to avoid being charged."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.sagemaker_session.delete_endpoint(model_name)\n",
    "model.sagemaker_session.delete_endpoint_config(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Clean-up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A. Delete the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.delete_model()"
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
