{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Jurassic-2 Grande Instruct on SageMaker through Model Packages\n",
    "\n",
    "This sample notebook shows you how to deploy **Jurassic-2 Grande Instruct** using Amazon SageMaker.\n",
    "\n",
    "## Pre-requisites:\n",
    "1. Before running this notebook, please make sure you got this notebook from the model catalog on SageMaker AWS Management Console.\n",
    "1. **Note**: This notebook contains elements which render correctly in Jupyter interface. Open this notebook from an Amazon SageMaker Notebook Instance or Amazon SageMaker Studio.\n",
    "1. Ensure that IAM role used has **AmazonSageMakerFullAccess**.\n",
    "1. This notebook is intended to work with **boto3 v1.25.4** or higher.\n",
    "\n",
    "## Contents:\n",
    "1. [Select model package](#1.-Select-model-package)\n",
    "1. [Create an endpoint and perform real-time inference](#2.-Create-an-endpoint-and-perform-real-time-inference)\n",
    "   1. [Create an endpoint](#A.-Create-an-endpoint)\n",
    "   1. [Interact with the model](#B.-Interact-with-the-model)\n",
    "   1. [Give it an instruction](#C.-Give-it-an-instruction)\n",
    "   1. [Create your own product description!](#D.-Create-your-own-product-description!)\n",
    "1. [Clean-up](#3.-Clean-up)\n",
    "   1. [Delete the endpoint](#A.-Delete-the-endpoint)\n",
    "   1. [Delete the model](#B.-Delete-the-model)\n",
    "    \n",
    "\n",
    "## Usage instructions\n",
    "You can run this notebook one cell at a time (By using Shift+Enter for running a cell)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Select model package\n",
    "Confirm that you received this notebook from the model catalog in SageMaker AWS Management Console."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_package_map = {\n",
    "    \"us-east-1\": \"arn:aws:sagemaker:us-east-1:865070037744:model-package/j2-grande-instruct-v1-1-033-92fee9d4f82f3b02a76ae298452f7378\",\n",
    "    \"us-east-2\": \"arn:aws:sagemaker:us-east-2:057799348421:model-package/j2-grande-instruct-v1-1-033-92fee9d4f82f3b02a76ae298452f7378\",\n",
    "    \"us-west-1\": \"arn:aws:sagemaker:us-west-1:382657785993:model-package/j2-grande-instruct-v1-1-033-92fee9d4f82f3b02a76ae298452f7378\",\n",
    "    \"us-west-2\": \"arn:aws:sagemaker:us-west-2:594846645681:model-package/j2-grande-instruct-v1-1-033-92fee9d4f82f3b02a76ae298452f7378\",\n",
    "    \"ca-central-1\": \"arn:aws:sagemaker:ca-central-1:470592106596:model-package/j2-grande-instruct-v1-1-033-92fee9d4f82f3b02a76ae298452f7378\",\n",
    "    \"eu-central-1\": \"arn:aws:sagemaker:eu-central-1:446921602837:model-package/j2-grande-instruct-v1-1-033-92fee9d4f82f3b02a76ae298452f7378\",\n",
    "    \"eu-west-1\": \"arn:aws:sagemaker:eu-west-1:985815980388:model-package/j2-grande-instruct-v1-1-033-92fee9d4f82f3b02a76ae298452f7378\",\n",
    "    \"eu-west-2\": \"arn:aws:sagemaker:eu-west-2:856760150666:model-package/j2-grande-instruct-v1-1-033-92fee9d4f82f3b02a76ae298452f7378\",\n",
    "    \"eu-west-3\": \"arn:aws:sagemaker:eu-west-3:843114510376:model-package/j2-grande-instruct-v1-1-033-92fee9d4f82f3b02a76ae298452f7378\",\n",
    "    \"eu-north-1\": \"arn:aws:sagemaker:eu-north-1:136758871317:model-package/j2-grande-instruct-v1-1-033-92fee9d4f82f3b02a76ae298452f7378\",\n",
    "    \"ap-southeast-1\": \"arn:aws:sagemaker:ap-southeast-1:192199979996:model-package/j2-grande-instruct-v1-1-033-92fee9d4f82f3b02a76ae298452f7378\",\n",
    "    \"ap-southeast-2\": \"arn:aws:sagemaker:ap-southeast-2:666831318237:model-package/j2-grande-instruct-v1-1-033-92fee9d4f82f3b02a76ae298452f7378\",\n",
    "    \"ap-northeast-2\": \"arn:aws:sagemaker:ap-northeast-2:745090734665:model-package/j2-grande-instruct-v1-1-033-92fee9d4f82f3b02a76ae298452f7378\",\n",
    "    \"ap-northeast-1\": \"arn:aws:sagemaker:ap-northeast-1:977537786026:model-package/j2-grande-instruct-v1-1-033-92fee9d4f82f3b02a76ae298452f7378\",\n",
    "    \"ap-south-1\": \"arn:aws:sagemaker:ap-south-1:077584701553:model-package/j2-grande-instruct-v1-1-033-92fee9d4f82f3b02a76ae298452f7378\",\n",
    "    \"sa-east-1\": \"arn:aws:sagemaker:sa-east-1:270155090741:model-package/j2-grande-instruct-v1-1-033-92fee9d4f82f3b02a76ae298452f7378\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from sagemaker import ModelPackage\n",
    "from sagemaker import get_execution_role\n",
    "import sagemaker as sage\n",
    "import boto3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check the version of boto3 - must be v1.25.4 or higher\n",
    "If you see a lower version number, pick another kernel to run the notebook, with Python 3.8 or above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.26.74'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boto3.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install ai21 python SDK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pip.repos.neuron.amazonaws.com\n",
      "Requirement already satisfied: ai21[SM] in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (1.0.5)\n",
      "Requirement already satisfied: requests in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from ai21[SM]) (2.28.1)\n",
      "Requirement already satisfied: boto3 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from ai21[SM]) (1.26.74)\n",
      "Requirement already satisfied: botocore<1.30.0,>=1.29.74 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from boto3->ai21[SM]) (1.29.74)\n",
      "Requirement already satisfied: s3transfer<0.7.0,>=0.6.0 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from boto3->ai21[SM]) (0.6.0)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from boto3->ai21[SM]) (1.0.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from requests->ai21[SM]) (1.26.8)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from requests->ai21[SM]) (2.1.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from requests->ai21[SM]) (2022.12.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from requests->ai21[SM]) (3.4)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from botocore<1.30.0,>=1.29.74->boto3->ai21[SM]) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.30.0,>=1.29.74->boto3->ai21[SM]) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "! pip install -U \"ai21[SM]\"\n",
    "import ai21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "region = boto3.Session().region_name\n",
    "if region not in model_package_map.keys():\n",
    "    raise (\"UNSUPPORTED REGION\")\n",
    "\n",
    "model_package_arn = model_package_map[region]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "role = get_execution_role()\n",
    "sagemaker_session = sage.Session()\n",
    "\n",
    "runtime_sm_client = boto3.client(\"runtime.sagemaker\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Create an endpoint and perform real-time inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to understand how real-time inference with Amazon SageMaker works, see [Documentation](https://docs.aws.amazon.com/sagemaker/latest/dg/deploy-model.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint_name = \"j2-grande-instruct\"\n",
    "\n",
    "content_type = \"application/json\"\n",
    "\n",
    "real_time_inference_instance_type = (\n",
    "    \"ml.p4d.24xlarge\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A. Create an endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------!"
     ]
    }
   ],
   "source": [
    "# create a deployable model from the model package.\n",
    "model = ModelPackage(\n",
    "    role=role, model_package_arn=model_package_arn, sagemaker_session=sagemaker_session\n",
    ")\n",
    "\n",
    "# Deploy the model\n",
    "predictor = model.deploy(1, real_time_inference_instance_type, endpoint_name=endpoint_name, \n",
    "                         model_data_download_timeout=3600,\n",
    "                         container_startup_health_check_timeout=600,\n",
    "                        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once endpoint has been created, you would be able to perform real-time inference."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B. Interact with the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can think of Jurassic-2 Grande Instruct as a smart auto-completion algorithm: give it some text as input and it will generate relevant text to naturally complete your input.\n",
    "\n",
    "These two helpful concepts are worth being familiar with:\n",
    "- **Prompt** - the input you provide to the model.\n",
    "- **Completion** - the output text the model generates."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Enter a simple prompt: \"To be, or\", and let the model complete it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " not to be: that is the question\n"
     ]
    }
   ],
   "source": [
    "response = ai21.Completion.execute(sm_endpoint=endpoint_name,\n",
    "                                   prompt=\"To be, or\",\n",
    "                                   maxTokens=4,\n",
    "                                   temperature=0,\n",
    "                                   numResults=1)\n",
    "\n",
    "print(response['completions'][0]['data']['text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the model identifies the beginning of a famous quote, and completes it correctly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C. Give it an instruction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model was specifically trained to follow natural language instructions. It is the most natural way to interact with large language models: simply tell the model what you want it to do, and it will follow.\n",
    "\n",
    "For this notebook, we will apply the model to creating a product description for an eCommerce site. Simply tell the model what you want it to do with a simple instruction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This funny t-shirt is perfect for anyone who enjoys a good laugh. The graphic on the front features an image of a cat with a mustache and glasses, and the text reads \"I mustache you a question.\" The shirt is made of 100% cotton and is soft and comfortable. It's sure to become a favorite in your wardrobe.\n"
     ]
    }
   ],
   "source": [
    "instruction = \"\"\"Write an engaging product description for clothing eCommerce site.\n",
    "Product: Humor Men's Graphic T-Shirt.\n",
    "Description:\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "response = ai21.Completion.execute(sm_endpoint=endpoint_name,\n",
    "                                   prompt=instruction,\n",
    "                                   maxTokens=100,\n",
    "                                   temperature=0,\n",
    "                                   numResults=1)\n",
    "\n",
    "print(response['completions'][0]['data']['text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adjust the parameters\n",
    "A useful parameter is the temperature. **You can increase creativity by tweaking the temperature.** With temperature 0, the model will always choose the most probable completion, so it will always be the same. Increasing the temperature will provide varying completions, where the completion may be different with every generation. We recommend starting with a value of 0.7."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This funny t-shirt is perfect for any guy with a sense of humor. It's made of high-quality cotton and it's comfortable to wear. The graphics are printed using the latest technology, so they won't fade or crack. The shirt comes in a variety of colors, so you can choose the one that best fits your personality. It's a great gift for any occasion, and it's sure to bring a smile to your face.\n",
      "=============\n",
      "This funny t-shirt is perfect for any guy who has a sarcastic sense of humor. The graphic design features a skull wearing a crown and the words \"I'm the King.\" It's sure to get laughs and make a bold statement.\n",
      "\n",
      "The shirt is made from high-quality cotton and is comfortable to wear. It's available in a range of sizes, so you can find the perfect fit for you.\n",
      "=============\n",
      "This funny T-shirt is perfect for any occasion. The graphic print reads \"I Just Can't Keep Calm, I'm A Mom\" and is sure to bring a smile to your face. The 100% cotton construction is soft and comfortable, and the relaxed fit allows for easy movement. Whether you're running errands or lounging around the house, this T-shirt is sure to keep you looking and feeling your best.\n",
      "=============\n"
     ]
    }
   ],
   "source": [
    "instruction = \"\"\"Write an engaging product description for clothing eCommerce site.\n",
    "Product: Humor Men's Graphic T-Shirt.\n",
    "Description:\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "response = ai21.Completion.execute(sm_endpoint=endpoint_name,\n",
    "                                   prompt=instruction,\n",
    "                                   maxTokens=100,\n",
    "                                   temperature=0.7,\n",
    "                                   numResults=3)\n",
    "\n",
    "# Note that multiple completions - this is due to numResults > 1\n",
    "for comp in response['completions']:\n",
    "    print(comp['data']['text'].strip())\n",
    "    print(\"=============\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Be specific in your prompt\n",
    "You can see that the model generated several versions. There may be times when you are looking for a stricter format - such as a single paragraph. Just ask the model to stick to it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This funny men's graphic t-shirt is perfect for any occasion. The shirt features a humorous saying on the front and is made from a soft and comfortable material. It's sure to become a favorite in your wardrobe.\n",
      "=============\n",
      "This funny t-shirt is perfect for anyone who enjoys a good laugh. The graphic on the front is of a grumpy old man, and the text says \"I Don't Like Mondays.\" It's made of soft, comfortable cotton and comes in a variety of colors.\n",
      "=============\n",
      "This funny t-shirt is perfect for anyone who loves a good laugh. It's made of 100% cotton, so it's comfortable to wear, and the graphics are printed on the front. The shirt is available in a variety of colors, so you can choose the one that best fits your style.\n",
      "=============\n"
     ]
    }
   ],
   "source": [
    "instruction = \"\"\"Write an engaging product description for clothing eCommerce site. Make it a single paragraph.\n",
    "Product: Humor Men's Graphic T-Shirt.\n",
    "Description:\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "response = ai21.Completion.execute(sm_endpoint=endpoint_name,\n",
    "                                   prompt=instruction,\n",
    "                                   maxTokens=100,\n",
    "                                   temperature=0.5,\n",
    "                                   numResults=3)\n",
    "\n",
    "for comp in response['completions']:\n",
    "    print(comp['data']['text'].strip())\n",
    "    print(\"=============\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Personalize your prompt\n",
    "The model can generate nice descriptions based on only an instruction, but they may not be aligned with your actual product. If you have special features, ask the model to include them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Einstein's famous quote about artificial intelligence being no match for natural stupidity is printed on this men's t-shirt. It's a fun way to show your disdain for AI and your support for human intelligence.\n",
      "=============\n",
      "Einstein's famous quote about AI is the perfect way to show off a sense of humor. This men's t-shirt is made of soft cotton and is comfortable to wear. The print is bold and eye-catching, and is sure to be a conversation starter.\n",
      "=============\n",
      "Are you a smart person? Do you enjoy making witty jokes and sarcastic comments? If so, this Humor Men's Graphic T-Shirt is perfect for you! The print on the front reads \"Artificial intelligence is no match for natural stupidity\", and it's sure to get a chuckle from those around you.\n",
      "\n",
      "The shirt is made of soft cotton and comes in a variety of colors. It's comfortable to wear and easy to clean. Whether you're wearing it to work or out with friends, this shirt is sure to make a statement.\n",
      "\n",
      "So, what are you waiting for? Get your Humor Men's Graphic T-Shirt today and show the world your smart and sassy side!\n",
      "=============\n"
     ]
    }
   ],
   "source": [
    "instruction = \"\"\"Write an engaging product description for clothing eCommerce site. Make sure to include the following features in the description.\n",
    "Product: Humor Men's Graphic T-Shirt with a print of Einstein's quote: \"artificial intelligence is no match for natural stupidity‚Äù\n",
    "Features:\n",
    "- Soft cotton\n",
    "- Short sleeve\n",
    "Description:\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "response = ai21.Completion.execute(sm_endpoint=endpoint_name,\n",
    "                                   prompt=instruction,\n",
    "                                   maxTokens=100,\n",
    "                                   temperature=0.7,\n",
    "                                   numResults=3)\n",
    "\n",
    "for comp in response['completions']:\n",
    "    print(comp['data']['text'].strip())\n",
    "    print(\"=============\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### More format restrictions?\n",
    "If you have several examples of your optimal output, you can feed the model with a few-shot prompt that includes several examples. Prompts like this are very useful when you want to enforce a certain format that is non-trivial to pick up from just one example. These prompts work best with base models; try to use them with [Jurassic-2 Grande](https://github.com/AI21Labs/SageMaker/blob/main/J2_Grande_example_model_use.ipynb) instead."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### D. Create your own product description!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Want to build your own product description? Here's your chance!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions to build the prompt\n",
    "def list_features(features):\n",
    "    return \"\\n\".join(\n",
    "        f\"- {feat}\" for feat in features\n",
    "    )\n",
    "\n",
    "def build_prompt(product, features):\n",
    "    example = \"Write product descriptions for fashion eCommerce site. Make sure to include the following features in the description.\\n\"\n",
    "    example += f\"Product: {product}\\n\"\n",
    "    example += \"Features:\\n\"\n",
    "    example += list_features(features)\n",
    "    example += \"\\nDescription:\\n\"\n",
    "    \n",
    "    return example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Product: (for example, 'Women's Boho Beach Dress') Women's Boho Beach Dress\n",
      "Features, separated by commas with no spaces: (for example, 'midi dress,swing hem,special for summer') midi dress,swing hem,special for summer\n"
     ]
    }
   ],
   "source": [
    "product = input(\"Product: (for example, \\'Women's Boho Beach Dress\\')\")\n",
    "features = input(\"Features, separated by commas with no spaces: (for example, \\'midi dress,swing hem,special for summer\\')\")\n",
    "your_prompt = build_prompt(product, features.split(\",\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This boho beach dress is perfect for summer days. It's made of lightweight fabric and has a swing hem. The midi length makes it comfortable to wear, and the print is eye-catching.\n",
      "=============\n",
      "The Boho Beach Dress is perfect for hot summer days. This midi dress has a swing hem and is made from lightweight fabric. The dress has a bohemian style that is perfect for beach vacations.\n",
      "=============\n",
      "This boho beach dress is perfect for summer. The midi dress has a beautiful swing hem and the floral pattern is eye-catching. The fabric is lightweight and breathable, making it comfortable to wear even in hot weather.\n",
      "=============\n"
     ]
    }
   ],
   "source": [
    "response = ai21.Completion.execute(sm_endpoint=endpoint_name,\n",
    "                                   prompt=your_prompt,\n",
    "                                   maxTokens=100,\n",
    "                                   temperature=0.7,\n",
    "                                   numResults=3)\n",
    "\n",
    "for comp in response['completions']:\n",
    "    print(comp['data']['text'].strip())\n",
    "    print(\"=============\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interested in learning more?\n",
    "Take a look at our [blog post](https://www.ai21.com/blog/building-cv-profile-generator-using-ai21-studio) to understand the process of building a good prompt."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Clean-up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A. Delete the endpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that you have successfully performed a real-time inference, you do not need the endpoint any more. You can terminate the endpoint to avoid being charged."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.sagemaker_session.delete_endpoint(endpoint_name)\n",
    "model.sagemaker_session.delete_endpoint_config(endpoint_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B. Delete the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.delete_model()"
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "conda_pytorch_p39",
   "language": "python",
   "name": "conda_pytorch_p39"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
