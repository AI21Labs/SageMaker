{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Jurassic-2 Ultra on SageMaker through Model Packages\n",
    "\n",
    "This sample notebook shows you how to deploy **Jurassic-2 Ultra** (formerly Jumbo Instruct) using Amazon SageMaker.\n",
    "\n",
    "Jurassic-2 Ultra is nothing short of a revolution! This cutting-edge large language model by AI21 Labs excels at diverse tasks such as question answering, summarization, long-form copy generation, and information extraction. What’s more, it supports a range of non-English languages including Spanish, French, German, Portuguese, Italian, and Dutch. Its unmatched quality stands testament to its power, making it the most outstanding Jurassic model ever. Brace yourself for a thrilling AI experience!\n",
    "\n",
    "\n",
    "## Pre-requisites:\n",
    "1. Before running this notebook, please make sure you got this notebook from the model catalog on SageMaker AWS Management Console.\n",
    "1. **Note**: This notebook contains elements which render correctly in Jupyter interface. Open this notebook from an Amazon SageMaker Notebook Instance or Amazon SageMaker Studio.\n",
    "1. Ensure that IAM role used has **AmazonSageMakerFullAccess**.\n",
    "1. This notebook is intended to work with **boto3 v1.25.4** or higher.\n",
    "\n",
    "## Contents:\n",
    "1. [Select model package](#1.-Select-model-package)\n",
    "1. [Create an endpoint and perform real-time inference](#2.-Create-an-endpoint-and-perform-real-time-inference)\n",
    "   1. [Create an endpoint](#A.-Create-an-endpoint)\n",
    "   1. [Interact with the model](#B.-Interact-with-the-model)\n",
    "   1. [Prompt with instructions](#C.-Prompt-with-instructions)\n",
    "   1. [Prompt with examples](#D.-Prompt-with-examples)\n",
    "1. [Clean-up](#3.-Clean-up)\n",
    "   1. [Delete the endpoint](#A.-Delete-the-endpoint)\n",
    "   1. [Delete the model](#B.-Delete-the-model)\n",
    "    \n",
    "\n",
    "## Usage instructions\n",
    "You can run this notebook one cell at a time (By using Shift+Enter for running a cell)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Select model package\n",
    "Confirm that you received this notebook from the model catalog in SageMaker AWS Management Console."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_package_map = {\n",
    "    \"us-east-1\": \"arn:aws:sagemaker:us-east-1:416407187090:model-package/j2-ultra-v1-1-053\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from sagemaker import ModelPackage\n",
    "from sagemaker import get_execution_role\n",
    "import sagemaker as sage\n",
    "import boto3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check the version of boto3 - must be v1.25.4 or higher\n",
    "If you see a lower version number, pick another kernel to run the notebook, with Python 3.8 or above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.26.74'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boto3.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install ai21 python SDK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pip.repos.neuron.amazonaws.com\n",
      "Requirement already satisfied: ai21[SM] in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (1.0.7)\n",
      "Requirement already satisfied: requests in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from ai21[SM]) (2.28.1)\n",
      "Requirement already satisfied: boto3 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from ai21[SM]) (1.26.74)\n",
      "Requirement already satisfied: botocore<1.30.0,>=1.29.74 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from boto3->ai21[SM]) (1.29.74)\n",
      "Requirement already satisfied: s3transfer<0.7.0,>=0.6.0 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from boto3->ai21[SM]) (0.6.0)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from boto3->ai21[SM]) (1.0.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from requests->ai21[SM]) (1.26.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from requests->ai21[SM]) (2022.12.7)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from requests->ai21[SM]) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from requests->ai21[SM]) (3.4)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from botocore<1.30.0,>=1.29.74->boto3->ai21[SM]) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.30.0,>=1.29.74->boto3->ai21[SM]) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "! pip install -U \"ai21[SM]\"\n",
    "import ai21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "region = boto3.Session().region_name\n",
    "if region not in model_package_map.keys():\n",
    "    raise (\"UNSUPPORTED REGION\")\n",
    "\n",
    "model_package_arn = model_package_map[region]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "role = get_execution_role()\n",
    "sagemaker_session = sage.Session()\n",
    "\n",
    "runtime_sm_client = boto3.client(\"runtime.sagemaker\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Create an endpoint and perform real-time inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style='color:Blue'> How to choose the best instance for my use case?</span>\n",
    "<span style='color:#0057FF'> When you create your endpoint, you need to choose the instance type to run the model on. Choosing the right instance is mainly a matter of economics. Depending on your use case, you probably want the most cost-effective instance possible. In this notebook we use one of the supported instances.</span>\n",
    "\n",
    "<span style='color:#0057FF'>Looking for the list of all supported instances? See</span> [here](https://docs.ai21.com/docs/choosing-the-right-instance-type-for-amazon-sagemaker-models#jurassic-2-ultra)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to understand how real-time inference with Amazon SageMaker works, see [Documentation](https://docs.aws.amazon.com/sagemaker/latest/dg/deploy-model.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint_name = \"j2-ultra\"\n",
    "\n",
    "content_type = \"application/json\"\n",
    "\n",
    "real_time_inference_instance_type = (\n",
    "    \"ml.p4d.24xlarge\"    # Recommended instance\n",
    "#     \"ml.g5.48xlarge\"   # Cheaper and faster - recommended for relatively short inputs/outputs\n",
    "#     \"ml.p4de.24xlarge\" # Recommended for long inputs/outputs and faster performance\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A. Create an endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------!"
     ]
    }
   ],
   "source": [
    "# create a deployable model from the model package.\n",
    "model = ModelPackage(\n",
    "    role=role, model_package_arn=model_package_arn, sagemaker_session=sagemaker_session\n",
    ")\n",
    "\n",
    "# Deploy the model\n",
    "predictor = model.deploy(1, real_time_inference_instance_type, endpoint_name=endpoint_name, \n",
    "                         model_data_download_timeout=3600,\n",
    "                         container_startup_health_check_timeout=600,\n",
    "                        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once endpoint has been created, you would be able to perform real-time inference."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B. Interact with the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can think of Jurassic-2 Ultra as a smart auto-completion algorithm: give it some text as input and it will generate relevant text to naturally complete your input.\n",
    "\n",
    "These two helpful concepts are worth being familiar with:\n",
    "- **Prompt** - the input you provide to the model.\n",
    "- **Completion** - the output text the model generates."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Enter a simple prompt: \"To be, or\", and let the model complete it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " not to be\n",
      "That is the question\n"
     ]
    }
   ],
   "source": [
    "response = ai21.Completion.execute(sm_endpoint=endpoint_name,\n",
    "                                   prompt=\"To be, or\",\n",
    "                                   maxTokens=4,\n",
    "                                   temperature=0,\n",
    "                                   numResults=1)\n",
    "\n",
    "print(response['completions'][0]['data']['text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the model identifies the beginning of a famous quote, and completes it correctly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C. Prompt with instructions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Why**? This model was specifically trained to follow natural language instructions. It is the most natural way to interact with large language models: simply tell the model what you want it to do, and it will follow.\n",
    "\n",
    "**When?** Drafting, seeking for inspiration, or when the format and guidelines are \"work in progress\".\n",
    "\n",
    "**How?** Just provide an instruction.\n",
    "\n",
    "For this notebook, we will apply the model to summarize chat conversations. The conversations are taken from the [samsum dataset](https://huggingface.co/datasets/samsum). We will start with providing the model a simple instruction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_to_summarize = \"\"\"Michael: Hey John!\n",
    "John: Oh! Hi Michael\n",
    "Michael: Why you always start conversation with these beautiful  gestures like oh!, O my goodness ?\n",
    "John: Because i know that you always target me to discuss about your new car, isn't it?\n",
    "Michael: Haha! yes, today i'll keep talking on same topic :p\n",
    "John: O my goodness! then please start because you will definitely ruin my weekend :(\n",
    "Michael: O this is not like that, i have decided to purchase the car, i delayed it due to some payment issues which now have been resolved. Now i can buy a new car.\n",
    "John: That's great! Finally, you are all set to purchase the car.\n",
    "Michael: O yes! my friend.\n",
    "John: Do you remember? i used to say that you didn't have money for your daily survival then how could you purchase this car? Now! i am very happy to hear that you sufficient money to purchase that car.\n",
    "Michael: So, would you go with me to receive Mercedes Benz 2.0 from showroom? \n",
    "John: Yes! my brother, it's a big day for you and i'll definitely go with you to receive this luxury Mercedes Benz.\n",
    "Michael: But, there is a condition that, i will drive Mercedes Benz to home.\n",
    "John: Haha!  Sure my friend.\n",
    "Michael: i decided to get this darling car, but there are certain priorities which need to be fulfilled first.\n",
    "John: You'll get your darling soon\n",
    "Michael: Wow! (y)\n",
    "John: OK then, see you on Saturday, Goodbye!\n",
    "Michael: Sure! Goodbye.\"\"\"\n",
    "\n",
    "instruction = f\"\"\"Summarize the following conversation.\n",
    "{chat_to_summarize}\n",
    "\n",
    "Summary:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Michael tells John that he finally has enough money to buy a new car, and that John can go with him to the dealership. John is happy for Michael and says that he will go with him.\n"
     ]
    }
   ],
   "source": [
    "response = ai21.Completion.execute(sm_endpoint=endpoint_name,\n",
    "                                   prompt=instruction,\n",
    "                                   maxTokens=200,\n",
    "                                   temperature=0,\n",
    "                                   numResults=1)\n",
    "\n",
    "print(response['completions'][0]['data']['text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Be specific in your prompt\n",
    "The model was asked to summarize the chat conversation in a general way. Depending on your requirements, you may require a a different style, such as specific number of bullets. You can ask the model to stick to it (in this case, 2 bullets):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Michael tells John that he finally has enough money to buy a new car.\n",
      "* John is happy for Michael and agrees to go with him to the dealership.\n"
     ]
    }
   ],
   "source": [
    "bullet_instruction = f\"\"\"Below is a conversation:\n",
    "{chat_to_summarize}\n",
    "##\n",
    "\n",
    "Summarize the above conversation in 2 bullets.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "response = ai21.Completion.execute(sm_endpoint=endpoint_name,\n",
    "                                   prompt=bullet_instruction,\n",
    "                                   maxTokens=100,\n",
    "                                   temperature=0,\n",
    "                                   numResults=1)\n",
    "\n",
    "print(response['completions'][0]['data']['text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adjust the parameters\n",
    "A useful parameter is the temperature. **You can increase creativity by tweaking the temperature.** With temperature 0, the model will always choose the most probable completion, so it will always be the same. Increasing the temperature will provide varying completions, where the completion may be different with every generation.\n",
    "*Note: in tasks such as summarization, you should use low temperature, somewhere between 0-0.2*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Michael tells John that he finally has enough money to buy a new car, and John agrees to go with him to the dealership.\n",
      "=============\n",
      "Michael tells John that he is going to purchase a new car, a Mercedes Benz, and John agrees to go with him to the showroom.\n",
      "=============\n",
      "Michael tells John that he finally has enough money to buy a new car, and that John should go with him to the dealership. John is excited and agrees.\n",
      "=============\n"
     ]
    }
   ],
   "source": [
    "response = ai21.Completion.execute(sm_endpoint=endpoint_name,\n",
    "                                   prompt=instruction,\n",
    "                                   maxTokens=200,\n",
    "                                   temperature=0.2,\n",
    "                                   numResults=3) # this will make the model generate 3 optional completions\n",
    "\n",
    "for comp in response['completions']:\n",
    "    print(comp['data']['text'].strip())\n",
    "    print(\"=============\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Explore several phrasing\n",
    "If you are working with instruction prompting, small changes in the phrasing of the instruction may have a significant impact on the completion. The following is another way of instruction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "another_prompt =f\"\"\"You are a professional summarizer, an AI assistant that excels at summarizing chats.\n",
    "You will be presented with a conversation between two users. Read it and summarize it.\n",
    "\n",
    "{chat_to_summarize}\n",
    "--\n",
    "Summary:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Michael has decided to purchase a new car, a Mercedes Benz. John is happy for Michael and will go with him to receive the car.\n"
     ]
    }
   ],
   "source": [
    "response = ai21.Completion.execute(sm_endpoint=endpoint_name,\n",
    "                                   prompt=another_prompt,\n",
    "                                   maxTokens=100,\n",
    "                                   temperature=0,\n",
    "                                   numResults=1)\n",
    "\n",
    "print(response['completions'][0]['data']['text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### D. Prompt with examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Why?** Examples are helpful in assisting the model to comprehend and generate responses that adhere to the intended format.\n",
    "\n",
    "**When?** Examples are particularly useful when there are stringent format constraints, a well-defined objective, and an overall structure to be maintained.\n",
    "\n",
    "**How?** To establish a pattern for the model to follow, present a few instances (“shots”) of input-output pairs in the prompt. This enables the model to mimic the pattern. Then, provide the input for a query example and allow the model to generate a suitable completion. This approach is commonly referred to as a \"*few-shot prompt*\".\n",
    "\n",
    "According to the specifications for this dataset, the summaries should: _\"(1) be rather short, (2) extract important pieces of information, (3) include names of interlocutors, (4) be written in the third person\"_. Using these examples, we can guide our model accordingly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a few-shot prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will build a few-shot prompt comprised of the following:\n",
    "\n",
    "1. Prefix with 3 examples. Each example contains the relevant inputs (a conversation) and the output (a summary). They are separated by \"##\".\n",
    "\n",
    "2. The query inputs. An unseen chat conversation for which we would like the model to output a summary. These should follow the same format of the inputs in the prefix."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we collect some example data for the prompt prefix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXAMPLES_DATA = [\n",
    "    {\"chat\": \"\"\"Ash: Thanks so much! I am feeling so much better. I'm gonna work on the next chapter as soon as I can. I'm hoping to actually work on it tonight, but I have to beta another story. Thanks again!!!\n",
    "Mollie: Please do! I love all your stories but this one cuts the cake. :) I'm glad to hear you're feeling better :D and have fun Beta-ing! :P\n",
    "Mollie: P.S. Can I ask dor a small-ish favour? Could you make Clara say (in that last chapter): \"run you clever boy\" or something like that? If not I get it :P\n",
    "Ash: I'm not sure if I can in the last chapter, BUT I was thinking about it...I might be able to make another itty bitty cameo with he...and I might be able to have her say it... I gotta think about how to incorporate it! \n",
    "Mollie: There is an option to edit chapters - it's really weird but manageable. Wither way, having Clara back would be exciting :D\n",
    "Ash: Yeah... I know how to do that. I just wasn't sure if it made sense for her to say \"clever boy.\" But I'm gonna try to have her pop back in. Maybe in the last chapter. Want to make such a lovely reviewer happy :)\n",
    "Ash: Maybe this will make up for it until we get there? \n",
    "Ash: <file_other>\n",
    "Mollie: Hey!! I'm so sorry I didn't reply earlier - I had a couple of trips going on and literally no time to check the Internet!!! :( Now my Inbox is stuffed with emails that need replying -_-\n",
    "Mollie: Anyhoo, can I say how honoured I am that I got to see a sneak peek of the chapter (do you do this to all of your reviewers?? ;) ) and how much it made me want to read more! The chapter's lovely; I can't wait to see everyone;s reactions to Ian's presence in New York. :D\n",
    "Mollie: One technical issue though - how on earth are you going to explain Ian's incredible late workload? Sorry, i'm just being picky... :P\n",
    "Ash: I'm glad you like the preview! No I only give certain people previews. If their comments have really touched me then I usually try to show my thanks by sending a preview. Chapter 27 picks up a couple months after Ian and Roses reconciliation. Ian did work in certain parts, like all day in Little Talks and several others. But you are right that he is behind, and I will make a comment to address that! Gotta keep ya all happy!!! ;) \n",
    "Mollie: Out of curiosity though, are you ever going to have Ian tell Rose about switching realities experience??\n",
    "Mollie: You could always have that as additional chapter, or you could have a chapter showing everyone's reactions to Ian and Rose being toegther (that would always be worth reading! :P) Either way, you have fun writing :D\n",
    "Ash: It's not my plan to have him reveal it. It was about the realization for Ian. About him seeing the truth that's always been there. I never felt that he needed to tell her about it. He just needed her.\n",
    "Mollie: Awww, that last line *Swoon*\n",
    "Mollie: But sure, it is your story :) You can do whatever you want :P\n",
    "Mollie: What I keep wondering is what will happen to Ian once he reached 2025 in his own timeline, how will he react ect. Sorry for bugging you like this, it's all very interesting :P \n",
    "Ash: I hope I didn't come across rude!!! I wasn't at all trying to do that!!! I've had that question before. It's all a bit timey wimey and weird. It's not like Quantum Leap where one replaces the original and the \"original\" is somewhere.\n",
    "Ash: It's more of he was given this gift of jumping forward, so see what his life is/what it could be. But he had to make the decision if he was going to follow through. Was he going to make it happen, or was he going to give up the one thing in his life that made it precious? Was he going to fight for Rose? Was he going to believe that she loved him and allow himself that love? Paradox-y yes. Does that help? \n",
    "Mollie: No, you didn't come off as rude - if anything, it made me think to myself: well done, you've just offended the author\" :P\n",
    "Mollie: As for your explanation... er yeah kinda? I get why you did it for the plot (which also makes the plot more interesting), I'm just imaging Ian's reactions when he finally reaches 2025 and and thinks about how he woul have jumped timelines every day... am I making sense? Think of it as me creating a fanfic in my head of an actual fanfic :P\"\"\", \n",
    "     \"summary\": \"Ash is feeling better and he will work on the next chapter as soon as he can. He has to beta another story tonight. Mollie likes all of his stories.\"},\n",
    "    {\"chat\": \"\"\"William: Hello Hobbs! A new update on our whereabouts. Just moved over to Merida after a long drive from Cancun. Empty roads giving you a weird feeling. We had all possible difficulties finding our airbnb accommodation as its address was like Marida, Caucel, Avenida 68, Puerta Sisal, Calle 31, Avenida Caucel 68, Calle 3/2419 B. After much asking around, as we don't have a navigation system here, and consulting our paltry maps, we gave up and phoned our host who navigated us to the house, which turned out to be located in a semi-fenced residential area outside the city. Quite a pretty and comfy place for that and entirely for us alone.\n",
    "William: <file_photo>\n",
    "William: So we finally had a goodnight's sleep, did some sightseeing in the capital of Yucatan today and are looking forward to reconnoiter the area tomorrow.\n",
    "William: <file_photo>\n",
    "Hobbs: Hi there! Many thanks for the details. Caucel rings a bell with me. Is it to the west of the city itself? A fairly new development?\n",
    "William: That's it. Brand new and still being developed. Following a wide and brand new avenida today, we ended up with this. <file_photo> And dense vegetation beyond!\n",
    "Hobbs: Looks like Mexico to me. But they'll pick up the continuation once they needed it. Practically minded as they are. And how did you like the city itself?\n",
    "William: We got stuck on the Plaza Mayor, this being Sunday. It was turned into a market square with stalls offering local food, craftsmanship products and household goods, surprising un-touristy. In front of Palacio del Gobierno, a supreme show of dancing in local costumes.\n",
    "William: <file_photo>\n",
    "Hobbs: Did you manage to get to the balcony of the Palacio on the first floor and get some photos from there?\n",
    "William: But of course!\n",
    "William: <file_photo>\n",
    "William: Theresa tried to prevent me from trespassing but you know me. Even managed to get to the loo there!\n",
    "Hobbs: Good boy! And how about the cathedral? Casa de Montejo? Is it still accessible or is it only a bank?\n",
    "William: Both, and Theresa intends to visit the cathedral again to take some more photos. I didn't find it that impressive, apart from the west facade of course. A small part of Casa de Montejo on the ground floor is a museum now, interiors with period furniture plus a small modern art gallery, quite pleasant though over-airconditioned, but the rest is a bank, I think.\n",
    "Hobbs: If I remember correctly they bought the building some time ago and financed its restoration. To have a good overview of the city, you should try a ride on an open double-decker bus.\n",
    "William: Planned for a day to come. Tomorrow we want to go to Sisal and drive along the coast to Progresso.\n",
    "Hobbs: You'd better stay in Sisal, enjoy the beach and absolutely try one of their fish restaurants. As far as I remember the road leading eastwards peters out after a few kms and you are nowhere.  Years back with my team we mapped the ruins of Xcopte temple east of the road but it took us a strenuous march and even worse kayaking. I don't think it's been made open to sightseeing. I'd give it a miss anyway, nothing spectacular.\n",
    "William: Thanks for the tip! We are planning though to drive down and visit Uxmal. Is it worth it?\n",
    "Hobbs: Absolutely! It is a must. Huge, well preserved, with a totally unique - oval - pyramid, el Piramide del Adivino. Plan one whole day for this site. It is exceptional. One of my favourites in this part of Yucatan.\n",
    "William: We will! I'm developing a slight liking for Maya architecture :-)\n",
    "Hobbs: I bet you are! Anyway please keep me posted about your travelling there.\n",
    "William: Sure. Your tips are invaluable to us. You'll hear from us soon!\"\"\", \n",
    "     \"summary\": \"William and Theresa have just moved to Merida. They had problems getting there. They like their accommodation and they enjoy their sightseeing in the capital of Yukatan. They are planning to go to Sisal and Uxmal.\"},\n",
    "    {\"chat\": \"\"\"Diana: Hi Chris! Karen told me that you know someone from AIESEC\n",
    "Chris: Hello Diana! Good to hear from you!\n",
    "Chris: Not only I know someone from AIESEC, but I'm working with them myself :) How can I help you? Are interested in one of the projects?\n",
    "Diana: Great! Thanks for replying so quickly :)\n",
    "Diana: I was browsing your website and looking for different opportunities. I am particularly interested in Asia and Northern America, my only problem is that I don't speak other language than English\n",
    "Chris: Ok, it doesn't necessarily mean that you won't be eligible to participate in projects in other countries. Especially in Asia we have a lot of opportunities for people who would like to teach English\n",
    "Diana: That's great news! Won't it be a problem that I'm not a teacher? I don't have any experience\n",
    "Chris: It all depends on what you would like to do, are you interested in being a volunteer or in something paid?\n",
    "Diana: I'm interested in travelling that's for sure, so I really want to go somewhere. If you have something that will allow me to get paid for my work and will be in line with my experience, that'd be absolutely wonderful.\n",
    "Diana: I'm open for being a volunteer as well - the only problem's that I may not be able to afford to pay for the accommodation.\n",
    "Chris: Most of the organisations we're cooperating with cover the cost of the accommodation of our volunteers. You usually pay for a plane ticket and food. Certain organisations offer pocket money\n",
    "Diana: Yes, I saw one really interesting offer from Japan. They're looking for someone who could teach English in high school, although they listed some nationalities - didn't mention British, quite surprising in my opinion. Does it mean that I can't apply?\n",
    "Chris: Could you please send me a link? We have a lot offers and it'd be easier for me to advice you if I know the offer\n",
    "Diana: Sure <file_other>\n",
    "Chris: Thanks!\n",
    "Chris: Okay, so, I think in this case it shouldn’t be a problem. You may not be regarded as a preferred candidate, but I don’t think that you’re not eligible. Also, if you’re really interested, I’ll gladly contact the organisers and ask if they are interested in your profile.\n",
    "Diana: That would be amazing! Thank you Chris!\n",
    "Chris: If this one doesn’t work out, and please, be aware that we’re in touch with people all over the world so it may happen that you won’t get the job you applied for, are you interested in another position?\n",
    "Diana: I think I’ll be happy to participate in any project in Japan (as a volunteer or not), unless it’s related to computers, IT, technology, etc. as I have absolutely no clue about that stuff\n",
    "Chris: And what about North America? You mentioned that you may be interested in this as well\n",
    "Diana: Yes, I think it’s pretty much the same as with Japan. I’m not too keen on being a teacher at a camp, but everything other than that would be great\n",
    "Chris: Got it! I will look for something suitable. May you send me your CV?\n",
    "Diana: <file_other>\n",
    "Chris: Thanks! If you have any questions, do not hesitate to ask :)\n",
    "Diana: Thank you! I really appreciate your help Chris. The whole idea is brilliant, but I admit it’s a bit overwhelming and confusing especially as you’re new to the whole thing\n",
    "Chris: No worries, I've heard that a lot and we're doing everything we can to facilitate the process and make it more user friendly\n",
    "Chris: We also highly recommend everyone to visit us in one of our offices, so if you live in London, I'll be happy to meet you\n",
    "Diana: Perfect!\"\"\", \n",
    "     \"summary\": \"Chris is working with the AIESEC. Diana is interested in AIESEC's projects in Asia and Northern America. She sent Chris an offer in which they are looking for an English teacher in high school in Japan. Chris will contact the organisers on behalf of Diana and will let her know what their answer is.\"},\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we use the following helper functions to construct the prefix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_single_example(chat, summary):\n",
    "    example = \"You are a professional summarizer, an AI assistant that excels at summarizing chats.\\nYou will be presented with a conversation between two users. Read it and summarize it.\\n\\n\"\n",
    "    example += chat\n",
    "    example += \"\\n--\\n\"\n",
    "    example += \"Summary:\\n\"\n",
    "    example += summary\n",
    "    \n",
    "    return example\n",
    "\n",
    "SEPARATOR = \"\\n\\n##\\n\\n\"\n",
    "\n",
    "FEW_SHOT_PREFIX = SEPARATOR.join(\n",
    "    make_single_example(x[\"chat\"], x[\"summary\"]) for x in EXAMPLES_DATA\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And finally, we create a function to handle query inputs and create the full prompt:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_chat_summary_prompt(chat):\n",
    "    \"\"\"\n",
    "    Create a few-shot prompt to generate a chat summary with Jurassic-2 models\n",
    "    The prompt contains a preset sequence of examples followed by the query chat\n",
    "    \"\"\"\n",
    "    return FEW_SHOT_PREFIX + SEPARATOR + make_single_example(chat, '')  # keep the summary blank and let the model generate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how this looks for the chat from before:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are a professional summarizer, an AI assistant that excels at summarizing chats.\n",
      "You will be presented with a conversation between two users. Read it and summarize it.\n",
      "\n",
      "Ash: Thanks so much! I am feeling so much better. I'm gonna work on the next chapter as soon as I can. I'm hoping to actually work on it tonight, but I have to beta another story. Thanks again!!!\n",
      "Mollie: Please do! I love all your stories but this one cuts the cake. :) I'm glad to hear you're feeling better :D and have fun Beta-ing! :P\n",
      "Mollie: P.S. Can I ask dor a small-ish favour? Could you make Clara say (in that last chapter): \"run you clever boy\" or something like that? If not I get it :P\n",
      "Ash: I'm not sure if I can in the last chapter, BUT I was thinking about it...I might be able to make another itty bitty cameo with he...and I might be able to have her say it... I gotta think about how to incorporate it! \n",
      "Mollie: There is an option to edit chapters - it's really weird but manageable. Wither way, having Clara back would be exciting :D\n",
      "Ash: Yeah... I know how to do that. I just wasn't sure if it made sense for her to say \"clever boy.\" But I'm gonna try to have her pop back in. Maybe in the last chapter. Want to make such a lovely reviewer happy :)\n",
      "Ash: Maybe this will make up for it until we get there? \n",
      "Ash: <file_other>\n",
      "Mollie: Hey!! I'm so sorry I didn't reply earlier - I had a couple of trips going on and literally no time to check the Internet!!! :( Now my Inbox is stuffed with emails that need replying -_-\n",
      "Mollie: Anyhoo, can I say how honoured I am that I got to see a sneak peek of the chapter (do you do this to all of your reviewers?? ;) ) and how much it made me want to read more! The chapter's lovely; I can't wait to see everyone;s reactions to Ian's presence in New York. :D\n",
      "Mollie: One technical issue though - how on earth are you going to explain Ian's incredible late workload? Sorry, i'm just being picky... :P\n",
      "Ash: I'm glad you like the preview! No I only give certain people previews. If their comments have really touched me then I usually try to show my thanks by sending a preview. Chapter 27 picks up a couple months after Ian and Roses reconciliation. Ian did work in certain parts, like all day in Little Talks and several others. But you are right that he is behind, and I will make a comment to address that! Gotta keep ya all happy!!! ;) \n",
      "Mollie: Out of curiosity though, are you ever going to have Ian tell Rose about switching realities experience??\n",
      "Mollie: You could always have that as additional chapter, or you could have a chapter showing everyone's reactions to Ian and Rose being toegther (that would always be worth reading! :P) Either way, you have fun writing :D\n",
      "Ash: It's not my plan to have him reveal it. It was about the realization for Ian. About him seeing the truth that's always been there. I never felt that he needed to tell her about it. He just needed her.\n",
      "Mollie: Awww, that last line *Swoon*\n",
      "Mollie: But sure, it is your story :) You can do whatever you want :P\n",
      "Mollie: What I keep wondering is what will happen to Ian once he reached 2025 in his own timeline, how will he react ect. Sorry for bugging you like this, it's all very interesting :P \n",
      "Ash: I hope I didn't come across rude!!! I wasn't at all trying to do that!!! I've had that question before. It's all a bit timey wimey and weird. It's not like Quantum Leap where one replaces the original and the \"original\" is somewhere.\n",
      "Ash: It's more of he was given this gift of jumping forward, so see what his life is/what it could be. But he had to make the decision if he was going to follow through. Was he going to make it happen, or was he going to give up the one thing in his life that made it precious? Was he going to fight for Rose? Was he going to believe that she loved him and allow himself that love? Paradox-y yes. Does that help? \n",
      "Mollie: No, you didn't come off as rude - if anything, it made me think to myself: well done, you've just offended the author\" :P\n",
      "Mollie: As for your explanation... er yeah kinda? I get why you did it for the plot (which also makes the plot more interesting), I'm just imaging Ian's reactions when he finally reaches 2025 and and thinks about how he woul have jumped timelines every day... am I making sense? Think of it as me creating a fanfic in my head of an actual fanfic :P\n",
      "--\n",
      "Summary:\n",
      "Ash is feeling better and he will work on the next chapter as soon as he can. He has to beta another story tonight. Mollie likes all of his stories.\n",
      "\n",
      "##\n",
      "\n",
      "You are a professional summarizer, an AI assistant that excels at summarizing chats.\n",
      "You will be presented with a conversation between two users. Read it and summarize it.\n",
      "\n",
      "William: Hello Hobbs! A new update on our whereabouts. Just moved over to Merida after a long drive from Cancun. Empty roads giving you a weird feeling. We had all possible difficulties finding our airbnb accommodation as its address was like Marida, Caucel, Avenida 68, Puerta Sisal, Calle 31, Avenida Caucel 68, Calle 3/2419 B. After much asking around, as we don't have a navigation system here, and consulting our paltry maps, we gave up and phoned our host who navigated us to the house, which turned out to be located in a semi-fenced residential area outside the city. Quite a pretty and comfy place for that and entirely for us alone.\n",
      "William: <file_photo>\n",
      "William: So we finally had a goodnight's sleep, did some sightseeing in the capital of Yucatan today and are looking forward to reconnoiter the area tomorrow.\n",
      "William: <file_photo>\n",
      "Hobbs: Hi there! Many thanks for the details. Caucel rings a bell with me. Is it to the west of the city itself? A fairly new development?\n",
      "William: That's it. Brand new and still being developed. Following a wide and brand new avenida today, we ended up with this. <file_photo> And dense vegetation beyond!\n",
      "Hobbs: Looks like Mexico to me. But they'll pick up the continuation once they needed it. Practically minded as they are. And how did you like the city itself?\n",
      "William: We got stuck on the Plaza Mayor, this being Sunday. It was turned into a market square with stalls offering local food, craftsmanship products and household goods, surprising un-touristy. In front of Palacio del Gobierno, a supreme show of dancing in local costumes.\n",
      "William: <file_photo>\n",
      "Hobbs: Did you manage to get to the balcony of the Palacio on the first floor and get some photos from there?\n",
      "William: But of course!\n",
      "William: <file_photo>\n",
      "William: Theresa tried to prevent me from trespassing but you know me. Even managed to get to the loo there!\n",
      "Hobbs: Good boy! And how about the cathedral? Casa de Montejo? Is it still accessible or is it only a bank?\n",
      "William: Both, and Theresa intends to visit the cathedral again to take some more photos. I didn't find it that impressive, apart from the west facade of course. A small part of Casa de Montejo on the ground floor is a museum now, interiors with period furniture plus a small modern art gallery, quite pleasant though over-airconditioned, but the rest is a bank, I think.\n",
      "Hobbs: If I remember correctly they bought the building some time ago and financed its restoration. To have a good overview of the city, you should try a ride on an open double-decker bus.\n",
      "William: Planned for a day to come. Tomorrow we want to go to Sisal and drive along the coast to Progresso.\n",
      "Hobbs: You'd better stay in Sisal, enjoy the beach and absolutely try one of their fish restaurants. As far as I remember the road leading eastwards peters out after a few kms and you are nowhere.  Years back with my team we mapped the ruins of Xcopte temple east of the road but it took us a strenuous march and even worse kayaking. I don't think it's been made open to sightseeing. I'd give it a miss anyway, nothing spectacular.\n",
      "William: Thanks for the tip! We are planning though to drive down and visit Uxmal. Is it worth it?\n",
      "Hobbs: Absolutely! It is a must. Huge, well preserved, with a totally unique - oval - pyramid, el Piramide del Adivino. Plan one whole day for this site. It is exceptional. One of my favourites in this part of Yucatan.\n",
      "William: We will! I'm developing a slight liking for Maya architecture :-)\n",
      "Hobbs: I bet you are! Anyway please keep me posted about your travelling there.\n",
      "William: Sure. Your tips are invaluable to us. You'll hear from us soon!\n",
      "--\n",
      "Summary:\n",
      "William and Theresa have just moved to Merida. They had problems getting there. They like their accommodation and they enjoy their sightseeing in the capital of Yukatan. They are planning to go to Sisal and Uxmal.\n",
      "\n",
      "##\n",
      "\n",
      "You are a professional summarizer, an AI assistant that excels at summarizing chats.\n",
      "You will be presented with a conversation between two users. Read it and summarize it.\n",
      "\n",
      "Diana: Hi Chris! Karen told me that you know someone from AIESEC\n",
      "Chris: Hello Diana! Good to hear from you!\n",
      "Chris: Not only I know someone from AIESEC, but I'm working with them myself :) How can I help you? Are interested in one of the projects?\n",
      "Diana: Great! Thanks for replying so quickly :)\n",
      "Diana: I was browsing your website and looking for different opportunities. I am particularly interested in Asia and Northern America, my only problem is that I don't speak other language than English\n",
      "Chris: Ok, it doesn't necessarily mean that you won't be eligible to participate in projects in other countries. Especially in Asia we have a lot of opportunities for people who would like to teach English\n",
      "Diana: That's great news! Won't it be a problem that I'm not a teacher? I don't have any experience\n",
      "Chris: It all depends on what you would like to do, are you interested in being a volunteer or in something paid?\n",
      "Diana: I'm interested in travelling that's for sure, so I really want to go somewhere. If you have something that will allow me to get paid for my work and will be in line with my experience, that'd be absolutely wonderful.\n",
      "Diana: I'm open for being a volunteer as well - the only problem's that I may not be able to afford to pay for the accommodation.\n",
      "Chris: Most of the organisations we're cooperating with cover the cost of the accommodation of our volunteers. You usually pay for a plane ticket and food. Certain organisations offer pocket money\n",
      "Diana: Yes, I saw one really interesting offer from Japan. They're looking for someone who could teach English in high school, although they listed some nationalities - didn't mention British, quite surprising in my opinion. Does it mean that I can't apply?\n",
      "Chris: Could you please send me a link? We have a lot offers and it'd be easier for me to advice you if I know the offer\n",
      "Diana: Sure <file_other>\n",
      "Chris: Thanks!\n",
      "Chris: Okay, so, I think in this case it shouldn’t be a problem. You may not be regarded as a preferred candidate, but I don’t think that you’re not eligible. Also, if you’re really interested, I’ll gladly contact the organisers and ask if they are interested in your profile.\n",
      "Diana: That would be amazing! Thank you Chris!\n",
      "Chris: If this one doesn’t work out, and please, be aware that we’re in touch with people all over the world so it may happen that you won’t get the job you applied for, are you interested in another position?\n",
      "Diana: I think I’ll be happy to participate in any project in Japan (as a volunteer or not), unless it’s related to computers, IT, technology, etc. as I have absolutely no clue about that stuff\n",
      "Chris: And what about North America? You mentioned that you may be interested in this as well\n",
      "Diana: Yes, I think it’s pretty much the same as with Japan. I’m not too keen on being a teacher at a camp, but everything other than that would be great\n",
      "Chris: Got it! I will look for something suitable. May you send me your CV?\n",
      "Diana: <file_other>\n",
      "Chris: Thanks! If you have any questions, do not hesitate to ask :)\n",
      "Diana: Thank you! I really appreciate your help Chris. The whole idea is brilliant, but I admit it’s a bit overwhelming and confusing especially as you’re new to the whole thing\n",
      "Chris: No worries, I've heard that a lot and we're doing everything we can to facilitate the process and make it more user friendly\n",
      "Chris: We also highly recommend everyone to visit us in one of our offices, so if you live in London, I'll be happy to meet you\n",
      "Diana: Perfect!\n",
      "--\n",
      "Summary:\n",
      "Chris is working with the AIESEC. Diana is interested in AIESEC's projects in Asia and Northern America. She sent Chris an offer in which they are looking for an English teacher in high school in Japan. Chris will contact the organisers on behalf of Diana and will let her know what their answer is.\n",
      "\n",
      "##\n",
      "\n",
      "You are a professional summarizer, an AI assistant that excels at summarizing chats.\n",
      "You will be presented with a conversation between two users. Read it and summarize it.\n",
      "\n",
      "Michael: Hey John!\n",
      "John: Oh! Hi Michael\n",
      "Michael: Why you always start conversation with these beautiful  gestures like oh!, O my goodness ?\n",
      "John: Because i know that you always target me to discuss about your new car, isn't it?\n",
      "Michael: Haha! yes, today i'll keep talking on same topic :p\n",
      "John: O my goodness! then please start because you will definitely ruin my weekend :(\n",
      "Michael: O this is not like that, i have decided to purchase the car, i delayed it due to some payment issues which now have been resolved. Now i can buy a new car.\n",
      "John: That's great! Finally, you are all set to purchase the car.\n",
      "Michael: O yes! my friend.\n",
      "John: Do you remember? i used to say that you didn't have money for your daily survival then how could you purchase this car? Now! i am very happy to hear that you sufficient money to purchase that car.\n",
      "Michael: So, would you go with me to receive Mercedes Benz 2.0 from showroom? \n",
      "John: Yes! my brother, it's a big day for you and i'll definitely go with you to receive this luxury Mercedes Benz.\n",
      "Michael: But, there is a condition that, i will drive Mercedes Benz to home.\n",
      "John: Haha!  Sure my friend.\n",
      "Michael: i decided to get this darling car, but there are certain priorities which need to be fulfilled first.\n",
      "John: You'll get your darling soon\n",
      "Michael: Wow! (y)\n",
      "John: OK then, see you on Saturday, Goodbye!\n",
      "Michael: Sure! Goodbye.\n",
      "--\n",
      "Summary:\n",
      "\n"
     ]
    }
   ],
   "source": [
    "few_shot_prompt = create_chat_summary_prompt(chat=chat_to_summarize)\n",
    "\n",
    "print(few_shot_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Michael and John are discussing about Michael's new car. Michael has decided to purchase the car and is waiting for Saturday to receive it. John is happy for Michael and will go with him to receive the car.\n",
      "=============\n",
      "Michael is buying a new car, a Mercedes Benz. John is happy for Michael and will go with him to receive the car.\n",
      "=============\n",
      "Michael and John are talking about Michael's new car. Michael has decided to purchase the car and is waiting for Saturday. John is happy for Michael and will go with him to receive the car.\n",
      "=============\n"
     ]
    }
   ],
   "source": [
    "response = ai21.Completion.execute(sm_endpoint=endpoint_name,\n",
    "                                   prompt=few_shot_prompt,\n",
    "                                   maxTokens=200,\n",
    "                                   temperature=0.2,\n",
    "                                   numResults=3) # this will make the model generate 3 optional completions\n",
    "\n",
    "for comp in response['completions']:\n",
    "    print(comp['data']['text'].strip())\n",
    "    print(\"=============\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the completions follow a similar pattern to the examples in the few-shot prompt."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interested in learning more?\n",
    "Take a look at our [blog post](https://www.ai21.com/blog/building-cv-profile-generator-using-ai21-studio) to understand the process of building a good prompt."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Clean-up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A. Delete the endpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that you have successfully performed a real-time inference, you do not need the endpoint any more. You can terminate the endpoint to avoid being charged."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.sagemaker_session.delete_endpoint(endpoint_name)\n",
    "model.sagemaker_session.delete_endpoint_config(endpoint_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B. Delete the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.delete_model()"
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
